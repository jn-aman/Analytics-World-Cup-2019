{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93368\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector as mysql\n",
    "db = mysql.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    passwd = \"\",\n",
    "    database = \"SopraSteria\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "\n",
    "query = \"select id from twitter ORDER BY id DESC LIMIT 1;\"\n",
    "\n",
    "## getting records from the table\n",
    "cursor.execute(query)\n",
    "\n",
    "## fetching all records from the 'cursor' object\n",
    "records = cursor.fetchall()\n",
    "\n",
    "last_id=records[0][0]\n",
    "print(last_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: ['world cup', 'cricket india', 'cricket pakistan', ' cricket sri lanka', 'cricket england', 'cricket afganistan', 'cricket australia', 'cricket bangladesh', 'cricket new zealand', 'cricket south africa', 'cricket west indies', 'ICC', 'BCCI', 'Kholi', 'Dhoni', 'Virat', 'Virat Kohli', 'Rohit Sharma', 'Shikhar Dhawan', 'MS Dhoni', 'Kedar Jadhav', 'Hardik Pandya', 'Bhuvneshwar Kumar', 'Kuldeep Yadav', 'Yuzvendra Chahal', 'Jasprit Bumrah', 'Mohammed Shami', 'Vijay Shankar', 'Dinesh Karthik', 'KL Rahul', 'Ravindra Jadeja', 'Shoaib Malik', 'Mohammad Hafeez', 'Sarfaraz Ahmed', 'Wahab Riaz', 'Mohammad Amir', 'Haris Sohail', 'Babar Azam', 'Imam-ul-Haq', 'Asif Ali', 'Imad Wasim', 'Fakhar Zaman', 'Eoin Morgan', 'Jason Roy', 'Jonny Bairstow', 'James Vince', 'Jos Buttler', 'Ben Stokes', 'Moeen Ali', 'Chris Woakes', 'Liam Dawson', 'Tom Curran', 'Liam Plunkett', 'Gulbadin Naib', 'Mohammad Shahzad', 'Noor Ali Zadran', 'Hazratullah Zazai', 'Rahmat Shah', 'Asghar Afghan', 'Hashmatullah Shahidi', 'Najibullah Zadran', 'Samiullah Shinwari', 'Mohammad Nabi', 'Aaron Finch', 'David Warner', 'Usman Khawaja', 'Steven Smith', 'Shaun Marsh', 'Marcus Stoinis', 'Alex Carey', 'Nathan Coulter-Nile', 'Jason Behrendorff', 'Kane Richardson', 'Mashrafe Mortaza', 'Tamim Iqbal', 'Liton Das', 'Soumya Sarkar', 'Mushfiqur Rahim', 'Mahmudullah Riyad', 'Shakib Al Hasan', 'Mohammad Mithun', 'Sabbir Rahman', 'Kane Williamson', 'Tom Blundell', 'Trent Boult', 'Colin de Grandhomme', 'Lockie Ferguson', ' Martin Guptill', 'Matt Henry', 'Tom Latham', 'Colin Munro', 'Faf du Plessis', 'Quinton de Kock', 'David Miller', 'JP Duminy', 'Hashim Amla', 'Aiden Markram', 'Rassie van der Dussen', 'Dwaine Pretorius', 'Andile Phehlukwayo', 'Dimuth Karunaratne', 'Angelo Mathews', 'Thisara Perera', 'Kusal Perera', 'Dhananjaya de Silva', 'Kusal Mendis', 'Isuru Udana', 'Milinda Siriwardana', 'Avishka Fernando']\n",
      "You are now connected to the streaming API.\n",
      "Tweet collected at 2019-06-10 09:13:49+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x98\\\\x82\\\\xF0\\\\x9F...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:49+00:00\n",
      "Tweet collected at 2019-06-10 09:13:49+00:00\n",
      "Tweet collected at 2019-06-10 09:13:49+00:00\n",
      "Tweet collected at 2019-06-10 09:13:50+00:00\n",
      "Tweet collected at 2019-06-10 09:13:50+00:00\n",
      "Tweet collected at 2019-06-10 09:13:50+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x87\\\\xA8\\\\xF0\\\\x9F...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:50+00:00\n",
      "Tweet collected at 2019-06-10 09:13:51+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x94\\\\xA5\\\\xE2\\\\x80...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:51+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x87\\\\xB0\\\\xF0\\\\x9F...' for column 'location' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:51+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x87\\\\xAE\\\\xF0\\\\x9F...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:51+00:00\n",
      "Tweet collected at 2019-06-10 09:13:51+00:00\n",
      "Tweet collected at 2019-06-10 09:13:51+00:00\n",
      "Tweet collected at 2019-06-10 09:13:51+00:00\n",
      "Tweet collected at 2019-06-10 09:13:51+00:00\n",
      "Tweet collected at 2019-06-10 09:13:51+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x87\\\\xAE\\\\xF0\\\\x9F...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:52+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x99\\\\x8C\\\\x0A\\\\x0A...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:50+00:00\n",
      "Tweet collected at 2019-06-10 09:13:52+00:00\n",
      "Tweet collected at 2019-06-10 09:13:52+00:00\n",
      "Tweet collected at 2019-06-10 09:13:52+00:00\n",
      "Tweet collected at 2019-06-10 09:13:52+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\xA4\\\\xA8\\\\xF0\\\\x9F...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:53+00:00\n",
      "Tweet collected at 2019-06-10 09:13:53+00:00\n",
      "Tweet collected at 2019-06-10 09:13:53+00:00\n",
      "Tweet collected at 2019-06-10 09:13:53+00:00\n",
      "Tweet collected at 2019-06-10 09:13:53+00:00\n",
      "Tweet collected at 2019-06-10 09:13:53+00:00\n",
      "Tweet collected at 2019-06-10 09:13:54+00:00\n",
      "Tweet collected at 2019-06-10 09:13:54+00:00\n",
      "Tweet collected at 2019-06-10 09:13:54+00:00\n",
      "Tweet collected at 2019-06-10 09:13:54+00:00\n",
      "Tweet collected at 2019-06-10 09:13:54+00:00\n",
      "Tweet collected at 2019-06-10 09:13:54+00:00\n",
      "Tweet collected at 2019-06-10 09:13:54+00:00\n",
      "Tweet collected at 2019-06-10 09:13:54+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:54+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x98\\\\x82\\\\xF0\\\\x9F...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x92\\\\x94\\\\x0A\\\\x0A...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x98\\\\x92' for column 'location' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:55+00:00\n",
      "Tweet collected at 2019-06-10 09:13:56+00:00\n",
      "Tweet collected at 2019-06-10 09:13:56+00:00\n",
      "Tweet collected at 2019-06-10 09:13:56+00:00\n",
      "Tweet collected at 2019-06-10 09:13:56+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x98\\\\x92 \\\\xF0...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:56+00:00\n",
      "Tweet collected at 2019-06-10 09:13:56+00:00\n",
      "Tweet collected at 2019-06-10 09:13:56+00:00\n",
      "Tweet collected at 2019-06-10 09:13:57+00:00\n",
      "Tweet collected at 2019-06-10 09:13:57+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x99\\\\x8C\\\\x0A\\\\x0A...' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:57+00:00\n",
      "Tweet collected at 2019-06-10 09:13:57+00:00\n",
      "Tweet collected at 2019-06-10 09:13:57+00:00\n",
      "Tweet collected at 2019-06-10 09:13:57+00:00\n",
      "Tweet collected at 2019-06-10 09:13:57+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x98\\\\x87' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:58+00:00\n",
      "Tweet collected at 2019-06-10 09:13:58+00:00\n",
      "Tweet collected at 2019-06-10 09:13:58+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x87\\\\xAE\\\\xF0\\\\x9F...' for column 'location' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:58+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x92\\\\x94' for column 'text' at row 1\")\n",
      "Tweet collected at 2019-06-10 09:13:58+00:00\n",
      "Tweet collected at 2019-06-10 09:13:58+00:00\n",
      "Tweet collected at 2019-06-10 09:13:58+00:00\n",
      "Tweet collected at 2019-06-10 09:13:58+00:00\n",
      "(1366, \"Incorrect string value: '\\\\xF0\\\\x9F\\\\x98\\\\x82\\\\xF0\\\\x9F...' for column 'text' at row 1\")\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import MySQLdb \n",
    "from dateutil import parser\n",
    "import time\n",
    "\n",
    "WORDS = [ \"world cup\",\"cricket india\",\"cricket pakistan\" ,\" cricket sri lanka\",\"cricket england\",\"cricket afganistan\",\n",
    "         \"cricket australia\",\"cricket bangladesh\",\"cricket new zealand\",\"cricket south africa\",\"cricket west indies\"\n",
    "        ,\"ICC\",\"BCCI\",\"Kholi\",\"Dhoni\",\"Virat\",\"Virat Kohli\", \"Rohit Sharma\", \"Shikhar Dhawan\", \"MS Dhoni\", \n",
    "         \"Kedar Jadhav\", \"Hardik Pandya\", \"Bhuvneshwar Kumar\", \"Kuldeep Yadav\", \"Yuzvendra Chahal\", \"Jasprit Bumrah\",\n",
    "         \"Mohammed Shami\", \"Vijay Shankar\", \"Dinesh Karthik\", \"KL Rahul\", \"Ravindra Jadeja\", \"Shoaib Malik\",\n",
    "         \"Mohammad Hafeez\", \"Sarfaraz Ahmed\" , \"Wahab Riaz\", \"Mohammad Amir\", \"Haris Sohail\", \"Babar Azam\", \n",
    "         \"Imam-ul-Haq\", \"Asif Ali\", \"Imad Wasim\",\"Fakhar Zaman\",\"Eoin Morgan\",\"Jason Roy\", \"Jonny Bairstow\", \n",
    "         \"James Vince\", \"Jos Buttler\" , \"Ben Stokes\", \"Moeen Ali\", \"Chris Woakes\", \"Liam Dawson\", \"Tom Curran\", \n",
    "         \"Liam Plunkett\",\"Gulbadin Naib\" , \"Mohammad Shahzad\" , \"Noor Ali Zadran\", \"Hazratullah Zazai\", \"Rahmat Shah\",\n",
    "         \"Asghar Afghan\", \"Hashmatullah Shahidi\", \"Najibullah Zadran\", \"Samiullah Shinwari\", \"Mohammad Nabi\",\n",
    "         \"Aaron Finch\", \"David Warner\", \"Usman Khawaja\", \"Steven Smith\", \"Shaun Marsh\", \"Marcus Stoinis\", \n",
    "         \"Alex Carey\" , \"Nathan Coulter-Nile\", \"Jason Behrendorff\", \"Kane Richardson\", \"Mashrafe Mortaza\" , \n",
    "         \"Tamim Iqbal\", \"Liton Das\",\"Soumya Sarkar\", \"Mushfiqur Rahim\", \"Mahmudullah Riyad\", \"Shakib Al Hasan\", \n",
    "         \"Mohammad Mithun\" , \"Sabbir Rahman\",\"Kane Williamson\", \"Tom Blundell\" , \"Trent Boult\", \"Colin de Grandhomme\",\n",
    "         \"Lockie Ferguson\",\" Martin Guptill\", \"Matt Henry\", \"Tom Latham\", \"Colin Munro\",\"Faf du Plessis\",\n",
    "         \"Quinton de Kock\", \"David Miller\", \"JP Duminy\", \"Hashim Amla\", \"Aiden Markram\", \"Rassie van der Dussen\", \n",
    "         \"Dwaine Pretorius\", \"Andile Phehlukwayo\",\"Dimuth Karunaratne\", \"Angelo Mathews\", \"Thisara Perera\", \n",
    "         \"Kusal Perera\",\"Dhananjaya de Silva\", \"Kusal Mendis\", \"Isuru Udana\", \"Milinda Siriwardana\",\n",
    "         \"Avishka Fernando\"]\n",
    "\n",
    "CONSUMER_KEY = \"eGLtUPqEDKrBWkkkPjnr2lEjb\"\n",
    "CONSUMER_SECRET = \"ooxJXCB9D944rUzFQ9txPH4gEPlBlU0abGwSuo8WWlyPCPeuzg\"\n",
    "ACCESS_TOKEN = \"140283345-LFqLOC9YjgLQ3YqJI9yuh0qEFUwwl4wIOQpreTJl\"\n",
    "ACCESS_TOKEN_SECRET = \"L708vY9b30qPXs4Ftu8maPuZHHG9asNcfozAmyqLe3F3h\"\n",
    "\n",
    "HOST = \"localhost\"\n",
    "USER = \"root\"\n",
    "PASSWD = \"\"\n",
    "DATABASE = \"SopraSteria\"\n",
    "\n",
    "# This function takes the 'created_at', 'text', 'screen_name' and 'tweet_id' and stores it\n",
    "# into a MySQL database\n",
    "def store_data(created_at, text, screen_name, tweet_id,location):\n",
    "    db=MySQLdb.connect(host=HOST, user=USER, passwd=PASSWD, db=DATABASE, charset=\"utf8\")\n",
    "    cursor = db.cursor()\n",
    "    insert_query = \"INSERT INTO twitter (tweet_id, screen_name, created_at,location, text) VALUES (%s, %s,%s, %s, %s)\"\n",
    "    cursor.execute(insert_query, (tweet_id, screen_name, created_at,location,text))\n",
    "    db.commit()\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "    return\n",
    "\n",
    "class StreamListener(tweepy.StreamListener):    \n",
    "    #This is a class provided by tweepy to access the Twitter Streaming API. \n",
    "\n",
    "    def on_connect(self):\n",
    "        # Called initially to connect to the Streaming API\n",
    "        print(\"You are now connected to the streaming API.\")\n",
    " \n",
    "    def on_error(self, status_code):\n",
    "        # On error - if an error occurs, display the error / status code\n",
    "        print('An Error has occured: ' + repr(status_code))\n",
    "        return False\n",
    " \n",
    "    def on_data(self, data):\n",
    "        if (time.time() - start_time) < limit:\n",
    "        #This is the meat of the script...it connects to your mongoDB and stores the tweet\n",
    "            try:\n",
    "               # Decode the JSON from Twitter\n",
    "                datajson = json.loads(data)\n",
    "\n",
    "                #grab the wanted data from the Tweet\n",
    "                text = datajson['text']\n",
    "                screen_name = datajson['user']['screen_name']\n",
    "                location=datajson['user'][\"location\"]\n",
    "                tweet_id = datajson['id']\n",
    "                created_at = parser.parse(datajson['created_at']) \n",
    "\n",
    "                #print out a message to the screen that we have collected a tweet\n",
    "                print(\"Tweet collected at \" + str(created_at))\n",
    "\n",
    "                #insert the data into the MySQL database\n",
    "                store_data(created_at, text, screen_name, tweet_id,location)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            return True\n",
    "        else:\n",
    "            return False;\n",
    "            \n",
    "start_time = time.time()\n",
    "limit = 10\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "#Set up the listener. The 'wait_on_rate_limit=True' is needed to help with Twitter API rate limiting.\n",
    "listener = StreamListener(api=tweepy.API(wait_on_rate_limit=True)) \n",
    "streamer = tweepy.Stream(auth=auth, listener=listener)\n",
    "print(\"Tracking: \" + str(WORDS))\n",
    "streamer.filter(track=WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[\"india\",\"pakistan\" ,\"sri lanka\",\"england\",\"afganistan\",\"australia\",\"bangladesh\",\"new zealand\",\"south africa\",\"west indies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT * FROM twitter where id > 93368'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT * FROM twitter where id > \"+str(last_id)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector as mysql\n",
    "db = mysql.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    passwd = \"\",\n",
    "    database = \"SopraSteria\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "\n",
    "query = \"SELECT * FROM twitter where id > \"+str(last_id)\n",
    "\n",
    "## getting records from the table\n",
    "cursor.execute(query)\n",
    "\n",
    "## fetching all records from the 'cursor' object\n",
    "records = cursor.fetchall()\n",
    "\n",
    "# Showing the data\n",
    "# for record in records:\n",
    "#     print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def urlify2(s):\n",
    "\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    s = s.replace('\\n','')\n",
    "    s = s.replace('rt','')\n",
    "    s = s.replace('RT','')\n",
    "\n",
    "    # Replace all runs of whitespace with a single dash\n",
    "#     s = re.sub(r\"\\s+\", '_', s)\n",
    "    return s\n",
    "\n",
    "def urlify(s):\n",
    "\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "\n",
    "    # Replace all runs of whitespace with a single dash\n",
    "    s = re.sub(r\"\\s+\", '_', s)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india',\n",
       " 'pakistan',\n",
       " 'sri_lanka',\n",
       " 'england',\n",
       " 'afganistan',\n",
       " 'australia',\n",
       " 'bangladesh',\n",
       " 'new_zealand',\n",
       " 'south_africa',\n",
       " 'west_indies',\n",
       " 'tweet']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_l=[urlify(i) for i in vocab]\n",
    "vocab_l\n",
    "vocab_l.append(\"tweet\")\n",
    "vocab_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_all=dict()\n",
    "def word_count(str1):\n",
    "    \n",
    "    counts = dict.fromkeys(vocab_l)\n",
    "    \n",
    "    words = vocab\n",
    "\n",
    "    for i in range(len(vocab)):\n",
    "            counts[vocab_l[i]]=str1.lower().count(vocab[i])\n",
    "            counts[\"tweet\"]=urlify2(str1)\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(records)):\n",
    "    counts_all[i]=word_count(records[i][5])\n",
    "df=pd.DataFrame.from_dict(counts_all, orient='index',columns=counts_all[0].keys())\n",
    "df.head()\n",
    "df=df.drop_duplicates()\n",
    "    \n",
    "from sqlalchemy import create_engine\n",
    "database_username = 'root'\n",
    "database_password = ''\n",
    "database_ip       = 'localhost'\n",
    "database_name     = 'SopraSteria'\n",
    "database_connection = create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                               format(database_username, database_password, \n",
    "                                                      database_ip, database_name))\n",
    "df.to_sql('country', con=database_connection, if_exists='append',chunksize=1000,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import MySQLdb \n",
    "for i in range(len(records)):\n",
    "    db=MySQLdb.connect(host=\"localhost\", user=\"root\", passwd=\"\", db=\"SopraSteria\", charset=\"utf8\")\n",
    "    cursor = db.cursor()\n",
    "    blob = TextBlob(records[i][5])\n",
    "    if blob.sentiment[0]==0:\n",
    "        senti=\"neutral\"\n",
    "    elif blob.sentiment[0]>0:\n",
    "        senti=\"positive\"\n",
    "    else:\n",
    "        senti=\"negative\"\n",
    "    \n",
    "    insert_query = \"INSERT INTO tweetsentiments (tweet, sentiment) VALUES (%s, %s)\"\n",
    "    cursor.execute(insert_query, (records[i][5], senti))\n",
    "    db.commit()\n",
    "    cursor.close()\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS =[\"Dhoni\",\"Virat\", \"Rohit Sharma\", \"Dhawan\",\n",
    "         \"Jadhav\", \"Hardik Pandya\", \"Bhuvneshwar Kumar\", \"Kuldeep Yadav\", \"Yuzvendra Chahal\", \"Jasprit Bumrah\",\n",
    "         \"Mohammed Shami\", \"Vijay Shankar\", \"Dinesh Karthik\", \"KL Rahul\", \"Ravindra Jadeja\", \"Shoaib Malik\",\n",
    "         \"Mohammad Hafeez\", \"Sarfaraz Ahmed\" , \"Wahab Riaz\", \"Mohammad Amir\", \"Haris Sohail\", \"Babar Azam\", \n",
    "         \"Imam-ul-Haq\", \"Asif Ali\", \"Imad Wasim\",\"Fakhar Zaman\",\"Eoin Morgan\",\"Jason Roy\", \"Jonny Bairstow\", \n",
    "         \"James Vince\", \"Jos Buttler\" , \"Ben Stokes\", \"Moeen Ali\", \"Chris Woakes\", \"Liam Dawson\", \"Tom Curran\", \n",
    "         \"Liam Plunkett\",\"Gulbadin Naib\" , \"Mohammad Shahzad\" , \"Noor Ali Zadran\", \"Hazratullah Zazai\", \"Rahmat Shah\",\n",
    "         \"Asghar Afghan\", \"Hashmatullah Shahidi\", \"Najibullah Zadran\", \"Samiullah Shinwari\", \"Mohammad Nabi\",\n",
    "         \"Aaron Finch\", \"David Warner\", \"Usman Khawaja\", \"Steven Smith\", \"Shaun Marsh\", \"Marcus Stoinis\", \n",
    "         \"Alex Carey\" , \"Nathan Coulter-Nile\", \"Jason Behrendorff\", \"Kane Richardson\", \"Mashrafe Mortaza\" , \n",
    "         \"Tamim Iqbal\", \"Liton Das\",\"Soumya Sarkar\", \"Mushfiqur Rahim\", \"Mahmudullah Riyad\", \"Shakib Al Hasan\", \n",
    "         \"Mohammad Mithun\" , \"Sabbir Rahman\",\"Kane Williamson\", \"Tom Blundell\" , \"Trent Boult\", \"Colin de Grandhomme\",\n",
    "         \"Lockie Ferguson\",\" Martin Guptill\", \"Matt Henry\", \"Tom Latham\", \"Colin Munro\",\"Faf du Plessis\",\n",
    "         \"Quinton de Kock\", \"David Miller\", \"JP Duminy\", \"Hashim Amla\", \"Aiden Markram\", \"Rassie van der Dussen\", \n",
    "         \"Dwaine Pretorius\", \"Andile Phehlukwayo\",\"Dimuth Karunaratne\", \"Angelo Mathews\", \"Thisara Perera\", \n",
    "         \"Kusal Perera\",\"Dhananjaya de Silva\", \"Kusal Mendis\", \"Isuru Udana\", \"Milinda Siriwardana\",\n",
    "         \"Avishka Fernando\",\"Jason Holder\", \"Evin Lewis\", \"Darren Bravo\", \"Chris Gayle\", \"Andre Russell\", \n",
    "        \"Carlos Brathwaite\", \"Nicholas Pooran\", \"Oshane Thomas\", \"Shai Hope\" , \"Shimron Hetmyer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def urlify2(s):\n",
    "\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    s = s.replace('\\n','')\n",
    "    s = s.replace('rt','')\n",
    "    s = s.replace('RT','')\n",
    "\n",
    "    # Replace all runs of whitespace with a single dash\n",
    "#     s = re.sub(r\"\\s+\", '_', s)\n",
    "    return s\n",
    "\n",
    "def urlify(s):\n",
    "\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "\n",
    "    # Replace all runs of whitespace with a single dash\n",
    "    s = re.sub(r\"\\s+\", '_', s)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[\"india\",\"pakistan\" ,\"sri lanka\",\"england\",\"afganistan\",\"australia\",\"bangladesh\",\"new zealand\",\"south africa\",\"west indies\"]\n",
    "vocab_l=[urlify(i) for i in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word=[urlify(i).lower() for i in WORDS]\n",
    "WORDS=[i.lower() for i in WORDS]\n",
    "word.append(\"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(str1):\n",
    "    counts = dict.fromkeys(word)\n",
    "\n",
    "    for i in range(len(WORDS)):\n",
    "        \n",
    "            counts[word[i]]=str1.lower().count(WORDS[i])\n",
    "            counts[\"tweet\"]=urlify2(str1)\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "counts_all = collections.defaultdict(dict)\n",
    "for w in vocab_l:\n",
    "    counts_all[w]={}\n",
    "for j in range(len(vocab)):\n",
    "    for i in range(len(records)):\n",
    "        if records[i][5].lower().count(vocab[j]) or (records[i][4] is not None and records[i][4].lower().count(vocab[j])):\n",
    "            counts_all[vocab_l[j]][i]=word_count(records[i][5])\n",
    "        \n",
    "    \n",
    "counts_all=dict(counts_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe_collection = {} \n",
    "for county in vocab_l:\n",
    "    dataframe_collection[county] = pd.DataFrame.from_dict(counts_all[county], orient='index',columns=word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "database_username = 'root'\n",
    "database_password = ''\n",
    "database_ip       = 'localhost'\n",
    "database_name     = 'SopraSteria'\n",
    "database_connection = create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                               format(database_username, database_password, \n",
    "                                                      database_ip, database_name))\n",
    "for county in vocab_l:\n",
    "    dataframe_collection[county].to_sql(name=county, con=database_connection, if_exists='append',index=False,chunksize=500)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
